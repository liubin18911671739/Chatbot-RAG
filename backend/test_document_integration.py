"""
æ–‡æ¡£å¤„ç†æœåŠ¡é›†æˆæµ‹è¯•
æµ‹è¯•å®Œæ•´çš„æ–‡æ¡£å¤„ç†ç®¡çº¿ï¼ŒåŒ…æ‹¬çœŸå®çš„å‘é‡åŒ–å’Œå­˜å‚¨
"""

import os
import sys
import tempfile
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.document_service import DocumentService
from services.embedding_service import EmbeddingService
from services.vector_service import VectorService


def create_test_documents(test_dir):
    """åˆ›å»ºæµ‹è¯•æ–‡æ¡£"""
    documents = {}
    
    # 1. åˆ›å»º TXT æ–‡æ¡£
    txt_file = os.path.join(test_dir, 'æ ¡å›­æŒ‡å—.txt')
    txt_content = """åŒ—äº¬ç¬¬äºŒå¤–å›½è¯­å­¦é™¢æ ¡å›­æŒ‡å—

ç¬¬ä¸€ç« ï¼šå›¾ä¹¦é¦†ä½¿ç”¨è¯´æ˜
å›¾ä¹¦é¦†ä½äºæ ¡å›­ä¸­å¿ƒä½ç½®ï¼Œå‘¨ä¸€è‡³å‘¨äº”æ—©8:00è‡³æ™š10:00å¼€æ”¾ã€‚
å­¦ç”Ÿå¯ä»¥ä½¿ç”¨å­¦ç”Ÿè¯å€Ÿé˜…å›¾ä¹¦ï¼Œæ¯æ¬¡æœ€å¤šå€Ÿ5æœ¬ï¼Œå€ŸæœŸ30å¤©ã€‚
å›¾ä¹¦é¦†æä¾›è‡ªä¹ å®¤ã€ç”µå­é˜…è§ˆå®¤å’Œå°ç»„è®¨è®ºå®¤ã€‚

ç¬¬äºŒç« ï¼šé£Ÿå ‚ä»‹ç»
å­¦æ ¡æœ‰ä¸‰ä¸ªé£Ÿå ‚ï¼Œåˆ†åˆ«æ˜¯ç¬¬ä¸€é£Ÿå ‚ã€ç¬¬äºŒé£Ÿå ‚å’Œæ¸…çœŸé£Ÿå ‚ã€‚
è¥ä¸šæ—¶é—´ä¸ºæ—©6:30è‡³æ™š8:00ã€‚
å­¦ç”Ÿå¯ä½¿ç”¨æ ¡å›­å¡æˆ–æ”¯ä»˜å®ã€å¾®ä¿¡æ”¯ä»˜ã€‚

ç¬¬ä¸‰ç« ï¼šæ ¡åŒ»é™¢æœåŠ¡
æ ¡åŒ»é™¢ä½äºä¸œé—¨é™„è¿‘ï¼Œæä¾›åŸºæœ¬åŒ»ç–—æœåŠ¡ã€‚
å·¥ä½œæ—¶é—´ä¸ºå‘¨ä¸€è‡³å‘¨äº”æ—©8:30è‡³æ™š5:00ã€‚
ç´§æ€¥æƒ…å†µè¯·æ‹¨æ‰“æ ¡å›­æ€¥æ•‘ç”µè¯ï¼š110ã€‚
"""
    
    with open(txt_file, 'w', encoding='utf-8') as f:
        f.write(txt_content)
    documents['txt'] = txt_file
    
    # 2. åˆ›å»º Markdown æ–‡æ¡£
    md_file = os.path.join(test_dir, 'è¯¾ç¨‹å¤§çº².md')
    md_content = """# äººå·¥æ™ºèƒ½åŸºç¡€è¯¾ç¨‹å¤§çº²

## è¯¾ç¨‹ä¿¡æ¯
- è¯¾ç¨‹åç§°ï¼šäººå·¥æ™ºèƒ½åŸºç¡€
- å­¦åˆ†ï¼š3å­¦åˆ†
- å­¦æ—¶ï¼š48å­¦æ—¶
- æˆè¯¾æ•™å¸ˆï¼šå¼ è€å¸ˆ

## è¯¾ç¨‹ç›®æ ‡
1. ç†è§£äººå·¥æ™ºèƒ½çš„åŸºæœ¬æ¦‚å¿µå’Œå‘å±•å†å²
2. æŒæ¡æœºå™¨å­¦ä¹ çš„åŸºæœ¬ç®—æ³•
3. äº†è§£æ·±åº¦å­¦ä¹ çš„åŸºæœ¬åŸç†
4. èƒ½å¤Ÿä½¿ç”¨Pythonè¿›è¡Œç®€å•çš„AIé¡¹ç›®å¼€å‘

## è¯¾ç¨‹å†…å®¹

### ç¬¬ä¸€éƒ¨åˆ†ï¼šäººå·¥æ™ºèƒ½æ¦‚è¿°ï¼ˆ8å­¦æ—¶ï¼‰
- äººå·¥æ™ºèƒ½çš„å®šä¹‰å’Œå†å²
- äººå·¥æ™ºèƒ½çš„åº”ç”¨é¢†åŸŸ
- äººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿

### ç¬¬äºŒéƒ¨åˆ†ï¼šæœºå™¨å­¦ä¹ åŸºç¡€ï¼ˆ16å­¦æ—¶ï¼‰
- ç›‘ç£å­¦ä¹ 
- æ— ç›‘ç£å­¦ä¹ 
- å¼ºåŒ–å­¦ä¹ 
- å¸¸ç”¨ç®—æ³•ï¼šå†³ç­–æ ‘ã€SVMã€ç¥ç»ç½‘ç»œ

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ·±åº¦å­¦ä¹ ï¼ˆ16å­¦æ—¶ï¼‰
- ç¥ç»ç½‘ç»œåŸºç¡€
- å·ç§¯ç¥ç»ç½‘ç»œ
- å¾ªç¯ç¥ç»ç½‘ç»œ
- Transformeræ¨¡å‹

### ç¬¬å››éƒ¨åˆ†ï¼šå®è·µé¡¹ç›®ï¼ˆ8å­¦æ—¶ï¼‰
- å›¾åƒåˆ†ç±»é¡¹ç›®
- æ–‡æœ¬æƒ…æ„Ÿåˆ†æ
- èŠå¤©æœºå™¨äººå¼€å‘

## è€ƒæ ¸æ–¹å¼
- å¹³æ—¶ä½œä¸šï¼š30%
- æœŸä¸­é¡¹ç›®ï¼š30%
- æœŸæœ«è€ƒè¯•ï¼š40%
"""
    
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write(md_content)
    documents['md'] = md_file
    
    # 3. åˆ›å»ºå¦ä¸€ä¸ª TXT æ–‡æ¡£
    txt2_file = os.path.join(test_dir, 'å®¿èˆç®¡ç†è§„å®š.txt')
    txt2_content = """å­¦ç”Ÿå®¿èˆç®¡ç†è§„å®š

ä¸€ã€ä½œæ¯æ—¶é—´
1. å®¿èˆæ¥¼å¼€æ”¾æ—¶é—´ï¼šæ—©6:00è‡³æ™š11:00
2. æ™š11:00åç¦æ­¢å¤–å‡ºï¼Œç‰¹æ®Šæƒ…å†µéœ€å‘å®¿ç®¡è€å¸ˆè¯·å‡
3. åˆä¼‘æ—¶é—´ï¼ˆ12:00-14:00ï¼‰è¯·ä¿æŒå®‰é™

äºŒã€å«ç”Ÿè¦æ±‚
1. æ¯å‘¨è¿›è¡Œä¸€æ¬¡å®¿èˆå«ç”Ÿæ£€æŸ¥
2. ä¸ªäººåºŠé“ºéœ€ä¿æŒæ•´æ´
3. å…¬å…±åŒºåŸŸç”±å€¼æ—¥ç”Ÿè´Ÿè´£æ¸…æ‰«

ä¸‰ã€å®‰å…¨è§„å®š
1. ä¸¥ç¦ä½¿ç”¨å¤§åŠŸç‡ç”µå™¨
2. ä¸¥ç¦ç§æ‹‰ç”µçº¿
3. å‘ç°å®‰å…¨éšæ‚£åŠæ—¶æŠ¥å‘Šå®¿ç®¡
4. è´µé‡ç‰©å“å¦¥å–„ä¿ç®¡

å››ã€è®¿å®¢åˆ¶åº¦
1. å¤–æ¥äººå‘˜éœ€åœ¨é—¨å«å¤„ç™»è®°
2. è®¿å®¢éœ€åœ¨æ™š10:00å‰ç¦»å¼€
3. å¼‚æ€§è®¿å®¢ä¸å¾—è¿›å…¥å®¿èˆæ¥¼å±‚
"""
    
    with open(txt2_file, 'w', encoding='utf-8') as f:
        f.write(txt2_content)
    documents['txt2'] = txt2_file
    
    return documents


def test_document_parsing():
    """æµ‹è¯•æ–‡æ¡£è§£æåŠŸèƒ½"""
    print("=" * 60)
    print("æµ‹è¯• 1: æ–‡æ¡£è§£æåŠŸèƒ½")
    print("=" * 60)
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•å’Œæµ‹è¯•æ–‡æ¡£
    with tempfile.TemporaryDirectory() as test_dir:
        documents = create_test_documents(test_dir)
        
        # åˆ›å»ºæ–‡æ¡£æœåŠ¡ï¼ˆä¸éœ€è¦å‘é‡æœåŠ¡ï¼‰
        doc_service = DocumentService()
        
        # æµ‹è¯•æ¯ä¸ªæ–‡æ¡£
        for doc_type, file_path in documents.items():
            print(f"\nè§£æ {doc_type.upper()} æ–‡æ¡£: {Path(file_path).name}")
            
            try:
                result = doc_service.parse_document(file_path)
                
                print(f"  âœ“ è§£ææˆåŠŸ")
                print(f"    - æ–‡æœ¬é•¿åº¦: {len(result['text'])} å­—ç¬¦")
                print(f"    - æ–‡ä»¶ç±»å‹: {result['metadata']['file_type']}")
                
                if 'pages' in result['metadata']:
                    print(f"    - é¡µæ•°: {result['metadata']['pages']}")
                if 'paragraphs' in result['metadata']:
                    print(f"    - æ®µè½æ•°: {result['metadata']['paragraphs']}")
                if 'lines' in result['metadata']:
                    print(f"    - è¡Œæ•°: {result['metadata']['lines']}")
                
            except Exception as e:
                print(f"  âœ— è§£æå¤±è´¥: {e}")
                return False
    
    print("\nâœ… æ–‡æ¡£è§£ææµ‹è¯•é€šè¿‡")
    return True


def test_text_chunking():
    """æµ‹è¯•æ–‡æœ¬åˆ†ç‰‡åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: æ–‡æœ¬åˆ†ç‰‡åŠŸèƒ½")
    print("=" * 60)
    
    with tempfile.TemporaryDirectory() as test_dir:
        documents = create_test_documents(test_dir)
        
        # åˆ›å»ºæ–‡æ¡£æœåŠ¡ï¼Œè®¾ç½®è¾ƒå°çš„åˆ†ç‰‡å¤§å°ä»¥ä¾¿æµ‹è¯•
        doc_service = DocumentService(chunk_size=200, chunk_overlap=50)
        
        txt_file = documents['txt']
        
        print(f"\nè§£ææ–‡æ¡£: {Path(txt_file).name}")
        result = doc_service.parse_document(txt_file)
        text = result['text']
        
        print(f"  - åŸå§‹æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        
        # æµ‹è¯•é€’å½’åˆ†ç‰‡
        print("\nä½¿ç”¨é€’å½’åˆ†ç‰‡ç­–ç•¥:")
        chunks = doc_service.chunk_text(text, metadata={'file': txt_file}, strategy="recursive")
        
        print(f"  âœ“ åˆ†ç‰‡æ•°é‡: {len(chunks)}")
        print(f"  âœ“ åˆ†ç‰‡å¤§å°èŒƒå›´: {min(len(c['text']) for c in chunks)} - {max(len(c['text']) for c in chunks)} å­—ç¬¦")
        
        # æ˜¾ç¤ºå‰3ä¸ªåˆ†ç‰‡çš„é¢„è§ˆ
        for i, chunk in enumerate(chunks[:3]):
            preview = chunk['text'][:50].replace('\n', ' ')
            print(f"  - åˆ†ç‰‡ {i}: {preview}... ({len(chunk['text'])} å­—ç¬¦)")
        
        # éªŒè¯å…ƒæ•°æ®
        if chunks[0]['metadata']['file'] == txt_file:
            print("  âœ“ å…ƒæ•°æ®æ­£ç¡®ä¼ é€’")
        
    print("\nâœ… æ–‡æœ¬åˆ†ç‰‡æµ‹è¯•é€šè¿‡")
    return True


def test_full_pipeline():
    """æµ‹è¯•å®Œæ•´çš„æ–‡æ¡£å…¥åº“æµç¨‹ï¼ˆéœ€è¦æ¨¡å‹ä¸‹è½½ï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: å®Œæ•´æ–‡æ¡£å…¥åº“æµç¨‹")
    print("=" * 60)
    
    print("\nâš ï¸  æ³¨æ„: æ­¤æµ‹è¯•éœ€è¦ä¸‹è½½ sentence-transformers æ¨¡å‹ï¼ˆ~471MBï¼‰")
    print("å¦‚æœæ˜¯é¦–æ¬¡è¿è¡Œï¼Œè¯·è€å¿ƒç­‰å¾…æ¨¡å‹ä¸‹è½½...")
    
    response = input("\næ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ")
    if response.lower() != 'y':
        print("è·³è¿‡å®Œæ•´æµç¨‹æµ‹è¯•")
        return True
    
    with tempfile.TemporaryDirectory() as test_dir:
        documents = create_test_documents(test_dir)
        
        print("\nåˆå§‹åŒ–æœåŠ¡...")
        # åˆ›å»ºæœåŠ¡å®ä¾‹
        embedding_service = EmbeddingService()
        vector_service = VectorService(dimension=384)
        doc_service = DocumentService(
            embedding_service=embedding_service,
            vector_service=vector_service,
            chunk_size=300,
            chunk_overlap=50
        )
        
        print("âœ“ æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        
        # å¤„ç†ç¬¬ä¸€ä¸ªæ–‡æ¡£
        txt_file = documents['txt']
        print(f"\nå¤„ç†æ–‡æ¡£: {Path(txt_file).name}")
        
        result = doc_service.ingest_document(txt_file, document_id='doc-1')
        
        if result['status'] == 'success':
            print(f"  âœ“ å…¥åº“æˆåŠŸ")
            print(f"    - æ–‡æ¡£ID: {result['document_id']}")
            print(f"    - åˆ†ç‰‡æ•°: {result['chunks_count']}")
            print(f"    - å‘é‡æ•°: {result['vectors_count']}")
            print(f"    - å‘é‡ID: {result['vector_ids'][:5]}...")
        else:
            print(f"  âœ— å…¥åº“å¤±è´¥: {result.get('error')}")
            return False
        
        # æµ‹è¯•æ£€ç´¢
        print("\næµ‹è¯•å‘é‡æ£€ç´¢...")
        query_text = "å›¾ä¹¦é¦†åœ¨å“ªé‡Œï¼Ÿ"
        print(f"  æŸ¥è¯¢: {query_text}")
        
        query_vector = embedding_service.get_embedding(query_text)
        search_results = vector_service.search(query_vector, top_k=3)
        
        print(f"  âœ“ æ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³ç»“æœ:")
        for i, item in enumerate(search_results, 1):
            preview = item['metadata'].get('text', '')[:50] if 'text' in item['metadata'] else ''
            print(f"    {i}. ç›¸ä¼¼åº¦={item['score']:.4f}: {preview}...")
        
        # æ‰¹é‡å¤„ç†æµ‹è¯•
        print("\næµ‹è¯•æ‰¹é‡æ–‡æ¡£å¤„ç†...")
        all_files = list(documents.values())
        
        def progress_callback(current, total, file_path):
            print(f"  è¿›åº¦: {current}/{total} - {Path(file_path).name}")
        
        batch_results = doc_service.batch_ingest_documents(all_files, progress_callback=progress_callback)
        
        success_count = sum(1 for r in batch_results if r['status'] == 'success')
        print(f"\n  âœ“ æ‰¹é‡å¤„ç†å®Œæˆ: {success_count}/{len(all_files)} æˆåŠŸ")
        
        # æœ€ç»ˆæ£€ç´¢æµ‹è¯•
        print("\næœ€ç»ˆæ£€ç´¢æµ‹è¯•...")
        test_queries = [
            "é£Ÿå ‚åœ¨å“ªé‡Œï¼Ÿ",
            "äººå·¥æ™ºèƒ½è¯¾ç¨‹æœ‰å¤šå°‘å­¦åˆ†ï¼Ÿ",
            "å®¿èˆå‡ ç‚¹å…³é—¨ï¼Ÿ"
        ]
        
        for query in test_queries:
            print(f"\n  æŸ¥è¯¢: {query}")
            query_vector = embedding_service.get_embedding(query)
            results = vector_service.search(query_vector, top_k=2)
            
            for i, item in enumerate(results, 1):
                print(f"    {i}. ç›¸ä¼¼åº¦={item['score']:.4f}")
    
    print("\nâœ… å®Œæ•´æµç¨‹æµ‹è¯•é€šè¿‡")
    return True


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("æ–‡æ¡£å¤„ç†æœåŠ¡é›†æˆæµ‹è¯•")
    print("=" * 60)
    
    tests = [
        ("æ–‡æ¡£è§£æ", test_document_parsing),
        ("æ–‡æœ¬åˆ†ç‰‡", test_text_chunking),
        ("å®Œæ•´æµç¨‹", test_full_pipeline)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            success = test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"\nâŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            results.append((test_name, False))
    
    # æ‰“å°æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    for test_name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{status} - {test_name}")
    
    success_count = sum(1 for _, success in results if success)
    print(f"\næ€»è®¡: {success_count}/{len(results)} æµ‹è¯•é€šè¿‡")
    
    if success_count == len(results):
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ–‡æ¡£å¤„ç†ç®¡çº¿åŠŸèƒ½æ­£å¸¸")
        return 0
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        return 1


if __name__ == "__main__":
    import sys
    sys.exit(main())
